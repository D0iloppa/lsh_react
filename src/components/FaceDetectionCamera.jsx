import React, { useRef, useEffect, useState, useCallback } from 'react';
import * as faceapi from 'face-api.js';

const FaceDetectionCamera = ({ onCapture }) => {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const [isModelLoaded, setIsModelLoaded] = useState(false);
  const [isDetecting, setIsDetecting] = useState(false);
  const [faceDetected, setFaceDetected] = useState(false);
  const [loadingProgress, setLoadingProgress] = useState(0);
  const [loadingStatus, setLoadingStatus] = useState('ì¤€ë¹„ ì¤‘...');
  const [error, setError] = useState(null);
  const [isFrontCamera, setIsFrontCamera] = useState(true);
  const [currentStream, setCurrentStream] = useState(null);

  // ë² ì´ìŠ¤ URLì„ ê³ ë ¤í•œ ëª¨ë¸ ê²½ë¡œ ìƒì„±
  const getModelPath = () => {
    const baseUrl = import.meta.env.BASE_URL || '/';
    return `${baseUrl}models`;
  };

  // ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
  const startVideo = useCallback(async (facingMode = 'user') => {
    try {
      // ê¸°ì¡´ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬
      if (currentStream) {
        currentStream.getTracks().forEach(track => track.stop());
      }

      console.log('ğŸ“¹ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‹œì‘...', facingMode);
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { 
          width: { ideal: 640 },
          height: { ideal: 480 },
          facingMode: facingMode
        } 
      });
      
      setCurrentStream(stream);
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        console.log('âœ… ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì„¤ì • ì™„ë£Œ');
      }
    } catch (error) {
      console.error('âŒ ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨:', error);
      setError(`ì¹´ë©”ë¼ ì ‘ê·¼ ì‹¤íŒ¨: ${error.message}`);
    }
  }, [currentStream]);

  // ì¹´ë©”ë¼ ì „í™˜ í•¨ìˆ˜
  const switchCamera = useCallback(async () => {
    const newFacingMode = isFrontCamera ? 'environment' : 'user';
    setIsFrontCamera(!isFrontCamera);
    await startVideo(newFacingMode);
  }, [isFrontCamera, startVideo]);

  // ì–¼êµ´ ì¸ì‹ ëª¨ë¸ ë¡œë“œ
  useEffect(() => {
    const loadModels = async () => {
      try {
        const modelPath = getModelPath();
        console.log('ğŸ”„ ëª¨ë¸ ê²½ë¡œ:', modelPath);
        
        setLoadingStatus('ëª¨ë¸ íŒŒì¼ í™•ì¸ ì¤‘...');
        setLoadingProgress(10);
        
        setLoadingStatus('TinyFaceDetector ë¡œë”© ì¤‘...');
        console.log('ğŸ”„ TinyFaceDetector ëª¨ë¸ ë¡œë”© ì‹œì‘...');
        await faceapi.nets.tinyFaceDetector.loadFromUri(modelPath);
        setLoadingProgress(40);
        console.log('âœ… TinyFaceDetector ëª¨ë¸ ë¡œë“œ ì™„ë£Œ');
        
        setLoadingStatus('FaceLandmark ë¡œë”© ì¤‘...');
        await faceapi.nets.faceLandmark68Net.loadFromUri(modelPath);
        setLoadingProgress(70);
        console.log('âœ… FaceLandmark68Net ëª¨ë¸ ë¡œë“œ ì™„ë£Œ');
        
        setLoadingStatus('FaceRecognition ë¡œë”© ì¤‘...');
        await faceapi.nets.faceRecognitionNet.loadFromUri(modelPath);
        setLoadingProgress(100);
        console.log('âœ… FaceRecognitionNet ëª¨ë¸ ë¡œë“œ ì™„ë£Œ');
        
        setLoadingStatus('ë¡œë”© ì™„ë£Œ!');
        setIsModelLoaded(true);
        console.log('ğŸ‰ ëª¨ë“  ëª¨ë¸ ë¡œë“œ ì„±ê³µ!');
        
        // ëª¨ë¸ ë¡œë“œ ì„±ê³µ í™•ì¸
        console.log('ğŸ“Š ëª¨ë¸ ìƒíƒœ í™•ì¸:');
        console.log('- TinyFaceDetector:', faceapi.nets.tinyFaceDetector.isLoaded);
        console.log('- FaceLandmark68Net:', faceapi.nets.faceLandmark68Net.isLoaded);
        console.log('- FaceRecognitionNet:', faceapi.nets.faceRecognitionNet.isLoaded);
        
      } catch (error) {
        console.error('âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨:', error);
        setError(`ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: ${error.message}`);
        setLoadingStatus('ë¡œë”© ì‹¤íŒ¨');
        
        // ìƒì„¸í•œ ì—ëŸ¬ ì •ë³´ ì œê³µ
        if (error.message.includes('404')) {
          setError(`ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: ${getModelPath()}`);
        } else if (error.message.includes('fetch')) {
          setError('ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.');
        }
      }
    };

    loadModels();
  }, []);

  // ì´ˆê¸° ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
  useEffect(() => {
    startVideo('user');

    return () => {
      if (currentStream) {
        currentStream.getTracks().forEach(track => track.stop());
        console.log('ğŸ”„ ì¹´ë©”ë¼ ìŠ¤íŠ¸ë¦¼ ì •ë¦¬ ì™„ë£Œ');
      }
    };
  }, []);

  // ì–¼êµ´ ì¸ì‹ ì‹œì‘
  const startFaceDetection = useCallback(async () => {
    if (!isModelLoaded || !videoRef.current || isDetecting) return;

    console.log('ğŸ” ì–¼êµ´ ì¸ì‹ ì‹œì‘...');
    setIsDetecting(true);
    
    const detectFaces = async () => {
      if (!videoRef.current || videoRef.current.paused || videoRef.current.ended) {
        setIsDetecting(false);
        return;
      }

      try {
        const detections = await faceapi
          .detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions({
            inputSize: 416,
            scoreThreshold: 0.5
          }))
          .withFaceLandmarks()
          .withFaceDescriptors();

        // ìº”ë²„ìŠ¤ì— ê°ì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
        if (canvasRef.current) {
          const canvas = canvasRef.current;
          const displaySize = { 
            width: videoRef.current.videoWidth, 
            height: videoRef.current.videoHeight 
          };
          
          faceapi.matchDimensions(canvas, displaySize);
          
          const ctx = canvas.getContext('2d');
          ctx.clearRect(0, 0, canvas.width, canvas.height);
          
          // ì „ë©´ ì¹´ë©”ë¼ì¼ ë•Œë§Œ ì¢Œìš° ë°˜ì „
          if (isFrontCamera) {
            ctx.save();
            ctx.scale(-1, 1);
            ctx.translate(-canvas.width, 0);
          }
          
          const resizedDetections = faceapi.resizeResults(detections, displaySize);
          
          if (resizedDetections.length > 0) {
            // ì–¼êµ´ ê°ì§€ ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            faceapi.draw.drawDetections(canvas, resizedDetections);
            faceapi.draw.drawFaceLandmarks(canvas, resizedDetections);
            
            // ì¶”ê°€ì ì¸ ì‹œê°ì  í”¼ë“œë°±
            resizedDetections.forEach((detection, index) => {
              const box = detection.detection.box;
              const score = detection.detection.score;
              
              // ë°•ìŠ¤ í…Œë‘ë¦¬ ê·¸ë¦¬ê¸°
              ctx.strokeStyle = score > 0.8 ? '#00ff00' : score > 0.6 ? '#ffff00' : '#ff0000';
              ctx.lineWidth = 3;
              ctx.strokeRect(box.x, box.y, box.width, box.height);
              
              // ì‹ ë¢°ë„ ì ìˆ˜ í‘œì‹œ
              ctx.fillStyle = ctx.strokeStyle;
              ctx.font = '16px Arial';
              ctx.fillText(`ì‹ ë¢°ë„: ${(score * 100).toFixed(1)}%`, box.x, box.y - 10);
            });
          }
          
          if (isFrontCamera) {
            ctx.restore();
          }
        }

        // ì–¼êµ´ ê°ì§€ ì‹œ ìë™ ì´¬ì˜
        if (detections.length > 0 && !faceDetected) {
          console.log('ğŸ“¸ ì–¼êµ´ ê°ì§€ë¨! 1ì´ˆ í›„ ìë™ ì´¬ì˜...');
          setFaceDetected(true);
          setTimeout(() => {
            capturePhoto();
            setFaceDetected(false);
          }, 1000);
        } else if (detections.length === 0) {
          setFaceDetected(false);
        }

      } catch (error) {
        console.error('âŒ ì–¼êµ´ ì¸ì‹ ì˜¤ë¥˜:', error);
      }

      if (isDetecting) {
        requestAnimationFrame(detectFaces);
      }
    };

    detectFaces();
  }, [isModelLoaded, isDetecting, faceDetected, isFrontCamera]);

  // ì‚¬ì§„ ì´¬ì˜ í•¨ìˆ˜
  const capturePhoto = useCallback(() => {
    if (!videoRef.current) return;

    console.log('ğŸ“· ì‚¬ì§„ ì´¬ì˜ ì¤‘...');
    const canvas = document.createElement('canvas');
    const video = videoRef.current;
    
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    
    const ctx = canvas.getContext('2d');
    
    // ì „ë©´ ì¹´ë©”ë¼ì¼ ë•Œë§Œ ì¢Œìš° ë°˜ì „
    if (isFrontCamera) {
      ctx.save();
      ctx.scale(-1, 1);
      ctx.translate(-canvas.width, 0);
    }
    
    ctx.drawImage(video, 0, 0);
    
    if (isFrontCamera) {
      ctx.restore();
    }
    
    const imageData = canvas.toDataURL('image/jpeg', 0.8);
    
    console.log('âœ… ì‚¬ì§„ ì´¬ì˜ ì™„ë£Œ!');
    
    if (onCapture) {
      onCapture(imageData);
    }
  }, [onCapture, isFrontCamera]);

  // ë¹„ë””ì˜¤ ë¡œë“œ ì™„ë£Œ ì‹œ ì–¼êµ´ ì¸ì‹ ì‹œì‘
  const handleVideoLoad = () => {
    console.log('âœ… ë¹„ë””ì˜¤ ë¡œë“œ ì™„ë£Œ');
    if (isModelLoaded) {
      startFaceDetection();
    }
  };

  // ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ì‹œ ì–¼êµ´ ì¸ì‹ ì‹œì‘
  useEffect(() => {
    if (isModelLoaded && videoRef.current && videoRef.current.readyState >= 2) {
      startFaceDetection();
    }
  }, [isModelLoaded, startFaceDetection]);

  // ì—ëŸ¬ ë°œìƒ ì‹œ UI
  if (error) {
    return (
      <div className="relative w-full max-w-2xl mx-auto">
        <div className="bg-red-100 border border-red-400 text-red-700 px-4 py-3 rounded">
          <h3 className="font-bold mb-2">ì˜¤ë¥˜ ë°œìƒ</h3>
          <p className="mb-3">{error}</p>
          
          <div className="mt-3 p-3 bg-yellow-50 border border-yellow-200 rounded">
            <p className="text-sm font-semibold mb-2">í˜„ì¬ ì„¤ì •:</p>
            <div className="text-sm space-y-1">
              <div>ë² ì´ìŠ¤ URL: {import.meta.env.BASE_URL}</div>
              <div>ëª¨ë¸ ê²½ë¡œ: {getModelPath()}</div>
              <div>ì˜ˆìƒ URL: {window.location.origin}{getModelPath()}/tiny_face_detector_model-weights_manifest.json</div>
            </div>
          </div>
          
          <button
            onClick={() => window.location.reload()}
            className="mt-3 px-4 py-2 bg-red-500 text-white rounded hover:bg-red-600"
          >
            í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
          </button>
        </div>
      </div>
    );
  }

  return (
    <div className="relative w-full max-w-2xl mx-auto">
      <div className="flex justify-center" style={{ marginBottom: '10px' }}>
        <button
            onClick={switchCamera}
            disabled={!isModelLoaded}
            className="px-6 py-2 bg-purple-500 text-white rounded-lg hover:bg-purple-600 disabled:bg-gray-400 disabled:cursor-not-allowed"
          >
            {/*isFrontCamera ? 'ğŸ“· í›„ë©´ì¹´ë©”ë¼' : 'ğŸ“± ì „ë©´ì¹´ë©”ë¼'*/}
            ğŸ”ƒ ì¹´ë©”ë¼ ì „í™˜
          </button>
      </div>
      <div className="relative bg-black rounded-lg overflow-hidden">
        <video
          ref={videoRef}
          autoPlay
          muted
          playsInline
          onLoadedData={handleVideoLoad}
          className="w-full h-auto"
          style={{ 
            maxHeight: '480px',
            transform: isFrontCamera ? 'scaleX(-1)' : 'none'
          }}
        />
        
        <canvas
          ref={canvasRef}
          className="absolute top-0 left-0 w-full h-full"
          style={{ 
            pointerEvents: 'none',
            transform: isFrontCamera ? 'scaleX(-1)' : 'none'
          }}
        />
        
        {/* ìƒíƒœ í‘œì‹œ */}
        <div className="absolute top-4 left-4 space-y-2">
          <div className={`px-3 py-1 rounded-full text-sm font-medium ${
            isModelLoaded ? 'bg-green-500 text-white' : 'bg-yellow-500 text-black'
          }`}>
            {isModelLoaded ? 'âœ… ëª¨ë¸ ì¤€ë¹„ì™„ë£Œ' : `ğŸ”„ ${loadingStatus} ${loadingProgress}%`}
          </div>
          
          {isDetecting && (
            <div className={`px-3 py-1 rounded-full text-sm font-medium ${
              faceDetected ? 'bg-blue-500 text-white animate-pulse' : 'bg-gray-500 text-white'
            }`}>
              {faceDetected ? 'ğŸ¯ ì–¼êµ´ê°ì§€ ğŸ“¸' : 'ğŸ” ì–¼êµ´íƒì§€ì¤‘...'}
            </div>
          )}
        </div>

        {/* ì¹´ë©”ë¼ ì „í™˜ ë²„íŠ¼ */}
        <button
          onClick={switchCamera}
          className="absolute top-4 right-4 px-3 py-2 bg-black bg-opacity-50 text-white rounded-full hover:bg-opacity-70 transition-all"
          title={`${isFrontCamera ? 'í›„ë©´' : 'ì „ë©´'} ì¹´ë©”ë¼ë¡œ ì „í™˜`}
        >
          {isFrontCamera ? 'ğŸ“·' : 'ğŸ“±'}
        </button>

        {/* ë””ë²„ê·¸ ì •ë³´ */}
        <div className="absolute bottom-4 left-4 text-xs text-white bg-black bg-opacity-50 px-2 py-1 rounded">
          {isFrontCamera ? 'ì „ë©´' : 'í›„ë©´'} ì¹´ë©”ë¼ | ëª¨ë¸ ê²½ë¡œ: {getModelPath()}
        </div>
      </div>
      
      <div className="mt-4 flex gap-4 justify-center">
        <button
          onClick={capturePhoto}
          disabled={!isModelLoaded}
          className="px-6 py-2 bg-blue-500 text-white rounded-lg hover:bg-blue-600 disabled:bg-gray-400 disabled:cursor-not-allowed"
        >
          ğŸ“¸ ìˆ˜ë™ ì´¬ì˜
        </button>
        
        <button
          onClick={() => {
            setIsDetecting(false);
            setTimeout(() => startFaceDetection(), 100);
          }}
          disabled={!isModelLoaded}
          className="px-6 py-2 bg-green-500 text-white rounded-lg hover:bg-green-600 disabled:bg-gray-400 disabled:cursor-not-allowed"
        >
          ğŸ”„ ì¸ì‹ ì¬ì‹œì‘
        </button>
      </div>
      
      <div className="mt-4 text-sm text-gray-600 text-center">
        ì–¼êµ´ì´ ê°ì§€ë˜ë©´ ìë™ìœ¼ë¡œ ì‚¬ì§„ì„ ì´¬ì˜í•©ë‹ˆë‹¤. ì¹´ë©”ë¼ ì „í™˜ ë²„íŠ¼ìœ¼ë¡œ ì „ë©´/í›„ë©´ ì¹´ë©”ë¼ë¥¼ ë°”ê¿€ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
      </div>
    </div>
  );
};

export default FaceDetectionCamera;